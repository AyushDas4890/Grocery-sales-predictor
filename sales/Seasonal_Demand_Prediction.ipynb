{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Seasonal Demand Prediction in Retail Stores\n",
                "\n",
                "## Problem Statement\n",
                "Predict demand for seasonal products in retail stores with high accuracy (>90%).\n",
                "\n",
                "## Problem Description\n",
                "Seasonal demand fluctuates. An ML model can analyze historical sales and environmental factors to predict trends.\n",
                "\n",
                "This project implements:\n",
                "1. **Advanced Feature Engineering**: Lags, Rolling Statistics, and Date-based features.\n",
                "2. **Ensemble Learning**:\n",
                "    - **Parallel Technique (Voting)**: Combining predictions from multiple independent models.\n",
                "    - **Sequential Technique (Boosting)**: Iteratively training models to correct errors of previous ones.\n",
                "3. **Detailed Evaluation**: Confusion Matrix (TP, TN, FP, FN) and ROC AUC Curves.\n",
                "4. **K-Fold Cross Validation**: Evaluating model performance robustly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "\n",
                "# Set visualization style\n",
                "sns.set(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Explore Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "df = pd.read_csv('Groceries_dataset.csv')\n",
                "\n",
                "# Convert Date to datetime\n",
                "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
                "\n",
                "# Aggregate data to get total daily sales (Demand)\n",
                "daily_sales = df.groupby('Date').size().reset_index(name='Sales_Count')\n",
                "\n",
                "# Sort by date to ensure lags are correct\n",
                "daily_sales = daily_sales.sort_values('Date')\n",
                "\n",
                "print(daily_sales.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Advanced Feature Engineering\n",
                "To achieve high accuracy, we need to provide the model with rich context about past sales trends."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Date-based Features\n",
                "daily_sales['Month'] = daily_sales['Date'].dt.month\n",
                "daily_sales['Day'] = daily_sales['Date'].dt.day\n",
                "daily_sales['DayOfWeek'] = daily_sales['Date'].dt.dayofweek\n",
                "daily_sales['Year'] = daily_sales['Date'].dt.year\n",
                "daily_sales['Quarter'] = daily_sales['Date'].dt.quarter\n",
                "daily_sales['Is_Weekend'] = daily_sales['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
                "\n",
                "# 2. Lag Features (Past Sales)\n",
                "# We include lags for the past 2 weeks to capture short-term and weekly patterns\n",
                "for lag in [1, 2, 3, 4, 5, 6, 7, 14]:\n",
                "    daily_sales[f'Sales_Lag_{lag}'] = daily_sales['Sales_Count'].shift(lag)\n",
                "\n",
                "# 3. Rolling Statistics\n",
                "# Capture moving averages and volatility\n",
                "for window in [3, 7, 14, 30]:\n",
                "    daily_sales[f'Rolling_Mean_{window}'] = daily_sales['Sales_Count'].rolling(window=window).mean()\n",
                "    daily_sales[f'Rolling_Std_{window}'] = daily_sales['Sales_Count'].rolling(window=window).std()\n",
                "\n",
                "# Drop NaNs created by lag/rolling\n",
                "daily_sales.dropna(inplace=True)\n",
                "\n",
                "# Define Seasons\n",
                "def get_season(month):\n",
                "    if month in [12, 1, 2]:\n",
                "        return 'Winter'\n",
                "    elif month in [3, 4, 5]:\n",
                "        return 'Spring'\n",
                "    elif month in [6, 7, 8]:\n",
                "        return 'Summer'\n",
                "    else:\n",
                "        return 'Fall'\n",
                "\n",
                "daily_sales['Season'] = daily_sales['Month'].apply(get_season)\n",
                "\n",
                "# Encode Season\n",
                "le = LabelEncoder()\n",
                "daily_sales['Season_Code'] = le.fit_transform(daily_sales['Season'])\n",
                "\n",
                "# Create Target Variable: Demand Level (Low, High)\n",
                "# Using binary classification with a median split for robust prediction\n",
                "daily_sales['Demand_Level'] = pd.qcut(daily_sales['Sales_Count'], q=2, labels=['Low', 'High'])\n",
                "daily_sales['Demand_Target'] = le.fit_transform(daily_sales['Demand_Level'])\n",
                "\n",
                "print(\"Data Shape after Feature Engineering:\", daily_sales.shape)\n",
                "print(daily_sales.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(14, 6))\n",
                "sns.lineplot(data=daily_sales, x='Date', y='Sales_Count', label='Daily Sales')\n",
                "sns.lineplot(data=daily_sales, x='Date', y='Rolling_Mean_7', label='7-Day Moving Avg', linewidth=2)\n",
                "plt.title('Daily Sales and Trends')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Implementation and Evaluation\n",
                "We train models and evaluate them using Accuracy, Confusion Matrix (TP, TN, FP, FN), and ROC AUC Curves."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare Data\n",
                "feature_cols = [\n",
                "    'Month', 'Day', 'DayOfWeek', 'Year', 'Quarter', 'Is_Weekend', 'Season_Code',\n",
                "    'Sales_Lag_1', 'Sales_Lag_2', 'Sales_Lag_3', 'Sales_Lag_4', 'Sales_Lag_5', 'Sales_Lag_6', 'Sales_Lag_7', 'Sales_Lag_14',\n",
                "    'Rolling_Mean_3', 'Rolling_Mean_7', 'Rolling_Mean_14', 'Rolling_Mean_30',\n",
                "    'Rolling_Std_3', 'Rolling_Std_7', 'Rolling_Std_14', 'Rolling_Std_30'\n",
                "]\n",
                "\n",
                "X = daily_sales[feature_cols]\n",
                "y = daily_sales['Demand_Target']\n",
                "\n",
                "# Train-Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
                "\n",
                "# Scaling\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# Initialize Models\n",
                "model1 = LogisticRegression(max_iter=3000, random_state=42, C=1.0)\n",
                "model2 = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
                "model3 = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=15)\n",
                "\n",
                "# Ensemble Models\n",
                "voting_clf = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('rf', model3)], voting='soft')\n",
                "gb_clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
                "\n",
                "models = {\n",
                "    'Logistic Regression': model1, \n",
                "    'Decision Tree': model2, \n",
                "    'Random Forest': model3,\n",
                "    'Voting Ensemble': voting_clf,\n",
                "    'Gradient Boosting': gb_clf\n",
                "}\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "\n",
                "for name, model in models.items():\n",
                "    # Train\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    \n",
                "    # Predict\n",
                "    y_pred = model.predict(X_test_scaled)\n",
                "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
                "    \n",
                "    # Accuracy\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    print(f\"\\n--- {name} ---\")\n",
                "    print(f\"Accuracy: {acc:.4f}\")\n",
                "    \n",
                "    # Confusion Matrix\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    tn, fp, fn, tp = cm.ravel()\n",
                "    \n",
                "    print(f\"Confusion Matrix:\\n{cm}\")\n",
                "    print(f\"True Negatives (TN): {tn}\")\n",
                "    print(f\"False Positives (FP): {fp}\")\n",
                "    print(f"False Negatives (FN): {fn
                }")\n",
                "    print(f\"True Positives (TP): {tp}\")\n",
                "    \n",
                "    # ROC Curve\n",
                "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    \n",
                "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
                "\n",
                "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('ROC Curves for All Models')\n",
                "plt.legend(loc=\"lower right\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. K-Fold Cross Validation\n",
                "Ensuring the high accuracy is consistent."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
                "\n",
                "# We use Gradient Boosting for CV as it's often the strongest\n",
                "cv_scores = cross_val_score(gb_clf, X, y, cv=kf, scoring='accuracy')\n",
                "print(f\"Gradient Boosting K-Fold CV Mean Accuracy: {cv_scores.mean():.4f}\")\n",
                "\n",
                "# Check Random Forest CV as well\n",
                "cv_scores_rf = cross_val_score(model3, X, y, cv=kf, scoring='accuracy')\n",
                "print(f\"Random Forest K-Fold CV Mean Accuracy: {cv_scores_rf.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "This notebook demonstrates a complete ML workflow with advanced feature engineering, ensemble learning, and detailed evaluation metrics including Confusion Matrices and ROC AUC curves."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}